m\chapter{Basic MiniAgda}

\newcommand{\dd}{\mathbf{d}}
\newcommand{\DD}{\mathbf{D}}
\newcommand{\cc}{\mathbf{c}}
\newcommand{\ff}{\mathbf{f}}

\begin{figure}[p]
\caption{MiniAgda syntax}
Expressions : \[e,t :  \lam x . e \vsp \EPi{x}{t}{t} \vsp e \; \vec{e} \vsp  \Set \vsp x \vsp \cc \vsp \DD \vsp \ff \vsp \dd\]
Patterns: \[ x  \vsp \cc \; \vec{p} \]
\end{figure}

MiniAgda is a small experimental version of Agda.
The current version of Agda is described by Ulf Norell in his thesis \cite{norell:thesis}.
\section{Syntax}
Let $\vec{a}$ denote a (possible empty) list of elements of category $a$
and $\diamond$ denote the empty list.
Int the following, these identifiers are used:
\begin{itemize}
\item for constructors : $\cc$ 
\item for data types : $\DD$
\item for functions : $\ff$
\item for definied constants : $\dd$
\item for variables : $x$
\end{itemize}
Now the various syntactical categories can be definied.
\\
Expressions (terms and types) $e,A,B$:  
\begin{itemize}
\item
abstraction: $ \lam x . e $ 
\item
dependent function space: $\EPi{x}{A}{B}$ 
\item 
application: $ e \; \vec{e} $ 
\item
type of all types: $ \Set $  $ \Set $ 

variables: $x$
\item
defined constructors, data types, functions and constants:
$ \cc \vsp \DD \vsp \ff \vsp \dd$
\end{itemize}
Patterns $p$:
\begin{itemize}
\item
variable pattern: $x$ 
\item
constructor pattern:$ \cc \; \vec{p} $ 
\item
inacessible pattern: $ \inacc{e} $ 
\end{itemize}
Declarations $\delta$:
\begin{itemize}
\item
inductive datatype: 
\[\data \; \DD \; \tau : t \; \vec{\gamma}\]  
\item
inductive function:
\[\fun \; \ff \; : \; t \; \vec{\kappa}\]
\item
constant:
\[\const \;  \dd \; : t \; = \; e \]
\item
mutual declaration:
\[\mutual \; \vec{\delta}\]
\end{itemize}
Constructor definition $\gamma$:
\begin{itemize}
\item
$ \cc \; : \; A $ 
\end{itemize}
Function clause definition
\begin{itemize}
\item
\[ \kappa :=  \ff \; \vec{p} = e \]
\end{itemize}
Telescopes:
\[ \tau := \diamond \vsp ( x : t ) \; \tau \]
A MiniAgda program consists of a list of declarations.
Each declaration adds newly defined constructs to the signature $\Sigma$.
The signature is empty at the beginning.
\section{Examples}
The best way to explain the syntax is through examples.
\subsection{Identity function}
Without defining new data types, we still can define some useful non recursive functions.
One example is the polymorphic identity function. 
Miniagda is monomorphic, so this is not really a polymorphic function, as you have to supply the
type as the first argument.
\begin{bsp}
$\const id : \EPi{A}{\Set}{A \ra A} = \lam{a}\lam{x}x$   
\end{bsp}
We simple add the defintion of $id$ to the signature:
\begin{bsp}
$\Sigma := \{ id : \EPi{A}{\Set}{A \ra A} = \lam{a}\lam{x}x$
\end{bsp}
\subsection{Booleans}
The booleans are an example of a non-inductive enumeration type.
\begin{bsp}
$\data \Bool : \Set$  \\
$\spc \ttt : \Bool $\\
$\spc \fff : \Bool $
\end{bsp}
Three new constants are added to the signature
\[ \Sigma := \{ \Bool : \Set , \ttt : \Bool , \fff : \Bool \} \]
\subsection{Natural Numbers}
First we declare the type of natural numbers:
\begin{bsp}
$\data \Nat : \Set$ \\
$\spc \zero : \Nat $\\
$\spc \suc : \Nat \ra \Nat$
\end{bsp}
then we declare the addition function by pattern matching:
\begin{bsp}
$\fun \add : \Nat \ra \Nat \ra \Nat$\\
$\spc \add x \; \zero = x $\\
$\spc \add x \; (\suc y) = \suc (\add x \; y)  $
\end{bsp}
\subsection{Lists}
Lists are an example of a parametrized data type:
\begin{bsp}
$\data \List ( A : \Set ) : \Set $ \\
$ \spc \nil : \List A  $\\
$ \spc \cons : A \ra \List A \ra \List A $
\end{bsp}
\subsection{Binary Trees}
The following introduces binary trees with leaf labeled with elements of $A$ and nodes labeld with elements of $B$:
\begin{bsp}
$\data \Tree ( A : \Set ) ( B : \Set ) : \Set $ \\
$ \spc \leaf : A \ra \Tree A \; B $\\
$ \spc \node : B \ra \Tree A \; B \ra \Tree A \; B $
\end{bsp}
The tree definition adds the following constans to the signature:
\begin{bsp}
$\Tree  : ( A : \Set ) \ra ( B : \Set ) \ra \Set$ \\
$ \spc \leaf : ( A : \Set ) \ra ( B : \Set ) \ra A \ra \Tree A \; B $ \\
$ \spc \node : ( A : \Set ) \ra ( B : \Set ) \ra A B \ra \Tree A \; B $
\end{bsp}
\section{Vectors}
The previous data types didn't use any dependent function space. 
Now things get more interesting. Vectors are an example of an inductive family of types.
They can be imagined as lists that store their length.
\begin{bsp}
$\data \vVec ( A : \Set ) : \Nat \ra \Set $ \\
$\spc \nil : \vVec A \; \zero  $\\
$ \spc \cons : \EPi{n}{\Nat}{ A \ra \vVec A \; n \ra \vVec A \; (\suc n)} $
\end{bsp}
Now let's define the $\head$ function that returns the first element of an vector. This operation should only be allowed for a non-empty vector.
With depentend types, we can express this in the type signature
\begin{bsp}
$ \fun \head : ( A : \Set ) \ra ( n : \Nat ) \ra \vVec A \; (\suc n) \ra A $
\end{bsp}
Now to the clause definition. We can explain the use inaccesible patterns here.
We need to pattern match to get the head element.
\begin{bsp}
$\head ? \; ? \; (\cons \; B \; m \; x \; xl) = x $
\end{bsp}
First, let's note that we don't need to pattern match against $\nil$.
Now what about the ? above. 
One might be inclined to use non-linear patterns:
\begin{bsp}
$\head \; B \; m \; (\cons  B \; m \; x \; xl) = x $
\end{bsp}
But we really don't have to check at runtime that the values at the corresponding arguments match -- it's guranteed for a well-typed program.
So to really capture the notion that the first two arguments are automatically istantiated by pattern matching against the inductive family argument, we use the inacessible pattern notation. The final definiton is:
\begin{bsp}
$ \fun \head : ( A : \Set ) \ra ( n : \Nat ) \ra \vVec A \; (\suc n) \ra A $\\
$ \spc \head \inacc{B} \; \inacc{m} \; (\cons \; B \; m \; x \; xl) = x $
\end{bsp}
\subsection{Equality}
The following is called Martin-L\"of equality.
The equality relation is defined by reflexivity.
\begin{bsp}
$\data \Eq ( A : \Set ) : A \ra A \ra \Set $ \\
$\spc \refl : A \ra \Eq A \; A  $
\end{bsp}
As a simple example, we can now prove that $ 0 + x = x $.
\begin{bsp}
$ \const \prof : \EPi{x}{\Nat}{\Eq \Nat (\add \zero x) x} $ \\ 
$ \spcx = \lam{y}\refl \Nat y$ 
\end{bsp}
Here we see that proof checking equals type checking.
Now if we want to prove $ x + 0 = x $, we need more effort.
The following does not pass the type checker
\begin{bsp}
$ \const \prof2 : \EPi{x}{\Nat}{\Eq \Nat (\add x \; \zero)  x} $ \\ 
$ \spcx \lam{y} \refl \Nat y$ 
\end{bsp}
The reason why is that type checker can only see definitional equality.
Note that addition was definied by recursion on the second argument. 
What we need is a recursive proof.

\begin{bsp}
$\fun \eqsucc : \EPi{x}{\Nat}\EPi{y}{\Nat} \Eq \Nat x \; y \ra \Eq \Nat (\suc x) \; (\suc y)$ \\
$\spc \eqsucc \inacc{x} \; \inacc{x} \; (\refl \inacc{\Nat} \; x) = \refl \Nat (\suc x)$\\
$\fun \tprof : ( x : \Nat ) \ra \Eq \Nat (\add \zero x) x$\\
$\spc \tprof \zero = \refl \Nat \zero$\\
$\spc \tprof (\suc x) = \eqsucc (\add \zero x)\; x \; (\tprof x)$
\end{bsp}

Recursive proofs need to be total (complete pattern matching and termination) to be correct.

\section{Universes}
To keep MiniAgda simple, $\Set$ is the type of all types.
This is known to be inconsistent.
It is quite complicated but possible to define a recusor.
Universe stratication can be used to avoid this inconsistency.

\section{Missing features}
Due to its use for interactivly building proofs, the full Agda has meta-variables that represent parts of tge proof that are still misssing. These 
Also, many bookkeeping arguments can be easily infered by the type checker,easying tedious pain for the user.
The user can mark these arguments as \emph{implicit}. The type checker will automatically infer them.
To keep MiniAgda simple, these features were not implemented.

\section{Type Checking}

\renewcommand\Check[4]{#1,#2\;\vdash\;#3\uparrow#4}
\newcommand\Infer[4]{#1,#2\;\vdash\;#3\downarrow#4}
\newcommand\IsType[3]{#1,#2\;\vdash\;#3\uparrow\Set}
\newcommand\EqVal[2]{\vdash\;#1\leftrightarrow#2}
\newcommand\Eval[3]{\mathrm{eval}\;#1\;#2\leadsto#3}
\newcommand\App[3]{\mathrm{app}\;#1,#2\leadsto#3}
\newcommand\AppFun[3]{\mathrm{appFun}\;#1,#2,\leadsto#3}
\newcommand\Fapp[6]{\mathrm{fapp}\;#1,#2,#3,#4,#5\leadsto#6}
\newcommand\Whnf[2]{\mathrm{whnf}\;#1\leadsto#2}
\newcommand\Lookup[3]{#1(#2) = #3}
\newcommand\LeqVal[2]{\vdash\;#1\leq#2}
\subsection{Values}
Values are the semantical interpretation of expressions.
For the interpretation of abstraction and the depentend function space, closures are used.
Values:
\[ v := \Set \vsp \Size \vsp vs \vsp \infty \vsp v \; \vec{v} \vsp \cc \vsp \ff \vsp \ e \; \rho vsp k \]
Environments:
\[ \rho := \diamond \vsp (x,v) \rho \]

The generic values $k$ are needed during type checking.
\subsection{Computation during type checking}
First of all, as types can depent on terms, it becomes necessary to perfom computation on terms during type checking.
The mutually recursive pair of functions 
\textbf{eval} and \textbf{app} do the job.
eval computes the weak head normal form of a expression.
\[ evaluation : \Eval{\rho}{e}{v}\]

application is the equivalent of beta reduction on values
\[ application : \App{v}{\vec{v}}{v'}\]

weak head normal form: 
\[ whnf : \Whnf{v}{v'} \]
\begin{figure}[p]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{\Set}{\Set}} 
          {} 
\end{array}
\]

\[
\begin{array}{c}
	  \infer{\Eval{\rho}{\cc}{\cc}} 
          {}

\end{array}
\]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{\ff}{\ff}} 
          {} 
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{\dd}{v}} 
          {\Lookup{\Sigma}{\dd}{e} & \Eval{\rho}{e}{v}} 
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{x}{v}} 
          {\Lookup{\rho}{\dd}{v}} 
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{\EPi{x}{t}{t'}{\EPi{x}{v}{t'}{\rho}}}}
          {\Eval{\rho}{t}{v}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Eval{\rho}{\lam x . e}{\lam{x}{e}{\rho}}}
		{} 
\end{array}
\]


\[
\begin{array}{c}
          
	  \infer{\Eval{\rho}{e \vec{e}}{v \vec{v}}}
          {\Eval{\rho}{e}{v} & \Eval{\rho}{\vec{e}}{\vec{v}}}
\end{array}
\]
\caption{Evaluation of expressions}
\end{figure}

\begin{figure}[p]

\[
\begin{array}{c}
          
	  \infer{\App{\lam{x}{e}{\rho}}{v \; \vec{v}}{v''}}
          {\Eval{(x,v)\rho}{e}{v'} & \App{v'}{\vec{v}}{v''}}
\end{array}
\]

\[
\begin{array}{c}
          
	  \infer{\App{\EPi{x}{w}{e}{\rho}}{v \; \vec{v}}{v''}}
          {\Eval{(x,v)\rho}{e}{v'} & \App{v'}{\vec{v}}{v''}}

\end{array}
\]

\[
\begin{array}{c}
          
	  \infer{\App{\ff}{\vec{v}}{v'}}
          {\AppFun{\ff}{\vec{v}}{v'}}
\end{array}
\]

\caption{application of values}
\end{figure}


\begin{figure}[p]
\[
\begin{array}{c}

\infer{\Whnf{\lam x . e \; \rho}{\lam x . e \; \rho}}{}

\end{array}
\]

\[
\begin{array}{c}
\infer{\Whnf{\EPi{x}{A}{B} \; \rho}{\EPi{x}{A}{B} \; \rho}}{}
\end{array}
\]

\[
\begin{array}{c}
\infer{\Whnf{e \; \rho}{v''}}
{\Eval{\rho}{e}{v'}
& \Whnf{v'}{v''} 
}
\end{array}
\]

\[
\begin{array}{c}
\infer{\Whnf{v \; \vec{v}}{v''}}
{
\Whnf{v}{v'}
& \Whnf{\vec{v}}{\vec{v}'}
& {\App{v'}{\vec{v}'}{v''}}
}
\end{array}
\]

\caption{weak head normal form}
\end{figure}

\subsection{Bidirectional type checking} 
For depentend types, a practice called \emph{bidirectional type checking} is used.
This means that the type checker has two modes:
one for checking that an expression has a certain type and one for infering the type of an expression.
These modes are again implement as functions
\[ \mathrm{check expression} :  \Check{\rho_1}{\rho_2}{e}{v}\]

and

\[ \mathrm{infer expression} : \Infer{\rho_1}{\rho_2}{e}{v}\]

in checking mode, the type checker might have to infer the type of the expression and then check that the infered
type is equal (convertible) against the proposed type.

Also, as a special case of check expression, the judgment 

\[ \mathrm{is type} : \IsType{\rho_1}{\rho_2}{e}\]

which checks that an expression is a type, i.e has type $\Set$.

so one needs equality between values, which is handled by the function
\[ \mathrm{eqVal} : \EqVal{v_1}{v_2} \]


\begin{figure}[p]
\[\begin{array}{c}
	  \infer{\Check{\rho_1}{\rho_2}{\lam x . e}{\EPi{y}{v}{e'}{\rho}}}
          { \Eval{(x,k)\;\rho}{e}{v'} & \Check{(x,k)\;\rho_1}{(x,v)\;\rho_2}{e'}{v'}} 
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Check{\rho_1}{\rho_2}{\EPi{x}{t}{t'}}{\Set}}
          {\IsType{\rho_1}{\rho_2}{t}  
	    & \Eval{(x,k)\;\rho_1}{t}{v}
	    & \IsType{(x,k)\rho}{{x,v}\rho_2}{t'}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Check{\rho_1}{\rho_2}{e}{v}} 
          { \Infer{\rho_1}{\rho_2}{e}{v'} & \EqVal{\rho_1}{\rho_2}{e}{v'}} 
\end{array}
\]
\caption{Checking expressions}
\end{figure}

\begin{figure}[p]
\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{x}{v}} 
          {\Lookup{\rho_2}{x}{v}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{\Set}{\Set}} 
          {}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{\ff}{v}} 
          {\Lookup{\Sigma}{\ff}{v}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{\cc}{v}} 
          {\Lookup{\Sigma}{\cc}{v}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{\DD}{v}} 
          {\Lookup{\Sigma}{\dd}{v}}
\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{e_1 \; e_2}{v''}}
{\Infer{\rho_1}{\rho_2}{e1}{\EPi{x}{v'}{e_3}{\rho}}
& \Check{\rho_1}{\rho_2}{e_2}{w}
& \Eval{\rho_1}{e_2}{v'}
& \Eval{(x,v')\rho}{e_3}{v''}}

\end{array}
\]

\[\begin{array}{c}
	  \infer{\Infer{\rho_1}{\rho_2}{e_1 \; e_2 \vec{e}}{v}
	  } 
          {\Infer{\rho_1}{\rho_2}{(e_1 \; e_2) \vec{e}}{v}}
\end{array}
\]



\caption{Infering type of expressions}
\end{figure}

\begin{figure}[p]
\caption{Untypes value equality checking}

\[\begin{array}{c}
	  \infer{\EqVal{\Set}{\Set}}
          {}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{k_n}{k_n}}
          {}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{\EPi{x}{v_1}{e_1}{\rho_1}}{\EPi{y}{v_2}{e_2}{\rho_2}}}
          {   \EqVal{v_1}{v} 
& \Eval{(x,k)\rho_1}{e_2}{v'_1}
& \Eval{(x,k)\rho_2}{e_2}{v'_2}
& \EqVal{v'_1}{v'_2}}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{\EPi{x}{v_1}{e_1}{\rho_1}}{\EPi{y}{v_2}{e_2}{\rho_2}}}
          {
\Eval{(x,k)\rho_1}{e_2}{v'_1}
& \Eval{(x,k)\rho_2}{e_2}{v'_2}
& \EqVal{v'_1}{v'_2}}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{\cc}{\cc}}
          {}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{\ff}{\ff}}
          {}
\end{array}\]

\[\begin{array}{c}
	  \infer{\EqVal{\DD}{\DD}}
          {}
\end{array}\]


\[\begin{array}{c}
	  \infer{\EqVal{v_1 \; \vec{v_1}}{v_2 \; \vec{v_2}}}
          {\EqVal{v_1}{v_2} & \EqVal{\vec{v_1}}{\vec{v_2}}}
\end{array}\]


\end{figure}

\subsubsection{Datatype declarations}
We require that datatype delcarations are strictly positive.
Otherwise there are inconsistencys (\cite{paulinmohring93inductive}).
\begin{definition}
X appears strictly positive in A if and only if
\begin{itemize}
\item
$ A = X$
\item
$ A = ( x : A' ) \ra B $ and X does not occur in $A'$  and appears strictly positive in B
\item
$ A = \DD \vec{p} \vec{v} $ and $X$ appears strictly positive in the parameters $\vec{p}$ 
and $X$ does not occur in $\vec{v}$.
\end{itemize}
\end{definition}
A delaration for $\DD$ is strictly positive if the $\dd$ and all parameters appear only
strictly positive in every constructor argument.
Our definition requires that datatypes are positivly parametrized.
Later this will be helpfull for subtyping.

\begin{bsp}
$\data \Bad : \Set $ \\
$\spc \ok : \Bad$\\
$\spc \bad : ((\Nat \ra \Bad) \ra \Bad) \ra \Bad  $
\end{bsp}
is not allowed because of the non-positive occurence of $\Bad$ in the argument of $\bad$.


\begin{bsp}
$\data \Bad : ( A : \Set ) : \Set $\\
$\spc \ok : \Bad A$\\
$\spc \bad : (A \ra \Bad) \ra \Bad A$
\end{bsp}
is not allowed because of the negative occurence of $A$ in the argument of $\bad$.

\subsubsection{Function declarations}

\subsubsection{Constant declaration}

\section{Pattern matching}
Dependend pattern matching was introduced by Thierry Coquand in \cite{coquand92pattern}.
The patterns for all the clauses of a function are assumed to be complete. This means that during runtime
it is guaranteed that matching always succeeds.

\chapter{Termination Checking}

\section{Structural recursion}

\begin{definition}[Order]
\[ O := \{ < , \leq , ? \} \]
\end{definition}
Axiom1:
\[ e \; < \; C \; \vec{e_1} \; e \; \vec{e_2} \]
\\
Axiom2:
\[ f \; \vec{e} \; \leq \; f \] 

Axiom 2 is needed for higher order data types like $\Ord$.

\begin{definition}[Order Addition]
\[
\begin{array}{l | c |c | c }

 +    &  <   &  \leq   &  ? \\
 \hline 
 <    &  <   & <       &  < \\
 \leq &  <   & \leq    &  <  \\
 ?    &  <   & \leq    &  ?
\end{array}
\]

\end{definition}


\begin{definition}[Order multiplication]
\[
\begin{array}{l | c |c | c}
 *   &  <  &  \leq & ? \\
\hline
  <   & <    & <    &   ? \\
 \leq & <    & \leq &   ?  \\
 ?    & ?    & ?    &   ?
\end{array}
\]
\end{definition}

\begin{definition}{Relating patterns and arguments}
\end{definition}

The following definitons are taken from \cite{abelAltenkirch:predStRec}

\begin{definition}
CallMatrix
A call matrix collects the comparisons of arguments and patterns of single call from function $f$ to function $g$
\end{definition}

\begin{definition}[Call Matrix multiplication]

\[(f,M_1,g) \times (g,M_2,h) := (f,M_1 \times M_2,h)\]
\end{definition}

\begin{definition}[Call Graph]
A finite set of Call matrices is called a \emph{call graph}
\end{definition}

\begin{definition}[Call Graph completion]
Call graph completion is closing the set under multiplication.
Completion of a finite set is also finite. 
\end{definition}

\section{Size change principle}

The termination criterion in \cite{abelAltenkirch:predStRec} can be replaced with the
simpler and more powerful criterion from \cite{lee01sizechange}
Their formalism is based on bipartit graphs instead of call matrixes, but these are
equivalent representations.

\begin{definition}
A callmatrix (f,M,f) is \emph{idempotent} if $ M \times M = M $ 
\end{definition}

\begin{definition}[Size change principle]
A function f is terminating, if every idempotent callmatrix  $ \in \mathrm{complete g} $ from f to f has a decreasing element $<$ on
the diagonal.
\end{definition}

David Wahlstedt proofs the soundness of the size-change principle for a depently typed language 
for first order data types (no function space in constructor arguments, so Axiom 2 is not needed ).
Andreas Abel has shown the soundness of the structual order defined by Axiom 1 and 2 for the simple typed
language foetus.
Note that the order from Axiom 1 and 2 is actually not valid in impredicative systems.

\begin{figure}[p]
\[
\mathrm{add}\begin{pmatrix}

\leq & ? \\
?    & < \\

\end{pmatrix}\mathrm{add}
\]
\caption{add call matrix}
\end{figure}

\begin{figure}[p]

\[
\mathrm{add'} \begin{pmatrix}

? & \leq \\
< & ?   \\

\end{pmatrix} \mathrm{add'}
\]

\caption{initial add' call matrix}

\end{figure}

\begin{figure}[p]

\[
\mathrm{add'} \begin{pmatrix}

< & ?    \\
? & <    \\

\end{pmatrix} \mathrm{add'}
\] 

\caption{idempotent add' call matrix}

\end{figure}

\section{Examples}

\subsection{Brouwer ordinals}
The so called Brouwer ordinal notations can be defined with
\begin{bsp}
$\data \Ord : \Set$ \\
$\sp \ozero : \Ord $\\
$\sp \olim : (\Nat \ra \Ord ) \ra \Ord $
\end{bsp}
This is an example of a higher-order data type, because the argument to $\olim$ contains a function space.
Now let's define ordinal addition:
\begin{bsp}
$\fun \addOrd : \Ord \ra \Ord \ra \Ord$\\
$\spc \addOrd x \; \ozero = x $\\
$\spc \addOrd x (\olim f) = \olim ( \lam{y} \addOrd  x \; (f \; y))  $
\end{bsp}
Axiom 2 is needed to show that the recursive call happens on a smaller argument.
\section{Extending the Order}
Definition of pair data type.
But now, the uncurried versions do no longer termination check.
The reason is that we need to keep the information.
\begin{definition}[MOrder]
\[ MO := \{ < , \leq , ? , MO^{r,n}\} \]
\end{definition}

\begin{definition}[Order Addition]
\[
\begin{array}{l | c |c | c | c}

 +    &  <   &  \leq   &  ? & M \\
 \hline 
 <    &  <   & <       &  < &  \\
 \leq &  <   & \leq    &  < &  \\
 ?    &  <   & \leq    &  ? &  \\
 M    &      &         &  M &  
\end{array}
\]

\end{definition}


\begin{definition}[Order multiplication]
\[
\begin{array}{l | c |c | c| c }
 *    &  <  &  \leq &   ? & M \\
\hline
  <   & <    & <    &   ? &   \\
 \leq & <    & \leq &   ? &   \\
 ?    & ?    & ?    &   ? &   \\
 M    &      &      &   ? &
\end{array}
\]
\end{definition}

\begin{definition}[Completion with extended order]
is also finite because matrices are only getting smaller or a collapsed to a single value.
\end{definition}

\section{Examples}


\subsection{Huet list reversion}
First, we present a peculiar list reversion algorithm.

The algorithm cannot be verified terminating.
Note that the recursive calls don't happen directly on subcomponents of the argument.
but are passed through another function.
We would need the information that revb does not increase the size of the list to ensure termination.
We can fix this by using vectors instead of lists:

Now the termination checker can verify the termination.
So we note that better type information helps the termination checker.
But using vectors instead of lists is not always easily possible.
Consider a filter function on Lists. We only know that this function does not increase the size, but
we don't know the exact length.
This is one of the reasons we will introduce a special size type in the next chapter.

\begin{figure}
$\mutual $  \\
$ \spc \fun \rev : \EPi{A}{\Set}{\List A \ra  \List A} $ \\
$ \spc \spc \rev .A \; (\nil A ) = \nil A$\\
$ \spc \spc \rev .A \; (\cons A \;x  \; xs) = \cons A \; (\reva A \; x \; xs) (\revb A \; x \; xs)$\\
$\ \spc \fun \reva : \EPi{A }{\Set}{A  \ra \List A \ra A}$\\
$ \spc \spc \reva .A \; a \; (\nil A ) = a$ \\
$\spc \spc \reva .A \; a (\cons A \; x \; xs) = \reva A \; x \; xs$\\
$\spc \fun \revb : \EPi{A}{\Set}{ A \ra \List A \ra \List A} $\\
$\spc \spc \revb .A \; a \; (\nil A ) = \nil A $\\
$\spc \spc \revb .A \; a (\cons A\;  x \; xs) = \rev A (\cons A \; a \; (\rev A \; (\revb A \; x \; xs)))$

\caption{reversion on Lists}  
\end{figure}
\begin{figure} 
$\mutual $ \\
$\spc \fun \rev : \EPi{n}{\Nat }{\EPi{A}{\Set }{\vVec A \; n \ra \vVec A \; n}}$\\
$\spc \spc \rev .zero \; .A  \; (\nil A) = \nil A $\\
$\spc \spc \rev .(\suc n) .\; A (\cons A \; n \; x \; xs) = $\\
$\spcx \cons A \; n \; (\reva n \; A \; x \; xs) (\revb n \; A \; x \; xs) $ \\
$\spc \fun \reva : \EPi{n}{\Nat}\EPi{A}{\Set}{A \ra Vec A \; n \ra A}$\\
$\spc \spc \reva .zero  \; .A \; a \; (\nil A) = a $\\
$\spc \spc \reva .(\suc n) .A \; a \; (\cons A \; n \; x \; xs) = \reva n \; A \; x \; xs $\\
$\spc \fun \revb : \EPi{n}{\Nat}{\EPi{A}{\Set}{A \ra \vVec A \; n \ra \vVec A \; n}}$\\
$ \spc \spc \revb .zero \; .A  \; a \; (\nil A) = \nil A $\\
$ \spc \spc \revb .(\suc n) \; .A \; a (\cons A \; n \; x \; xs) = $\\
$ \spcx \rev (\suc n) A (\cons A \; n \; a (\rev n \; A \; x \; xs))$
\caption{reversion on vectors}  
\end{figure}  

\chapter{Adding a Size Type}
Traditionally, size annotation have been used in the typing rules.
We take a different approach.
Wie add a primitive size type, and then use the current termination checker to see that the size is 
decreasing.
\section{Syntax}

Expressions:
\begin{itemize}
\item
size type: $ \Size $ 
\item
size succesor: $\s e $ 
\item
infinity: $\infty$ 
\end{itemize}
Patterns:
\begin{itemize}
\item
size succesor pattern:$ \s p $ 
\end{itemize}
Note that we also have variables of type $\Size$.
As such, expressions of type size form the stage expression of Barthe et. al :  $ i , \s i $ and $ \infty $ .
\section{Sized types definition}
We now declare what a sized type is.
\begin{definition}
A datatype D is a sized type, if $ \Size \ra A $ is its type
For every constructor 
\begin{itemize}
\item
it begins with $(i: Size)$
\item
the result type is $D \dots (\s i) \dots $
\item
every rec. argument is of the form $ D \dots i \dots $
\end{itemize}
\end{definition}
\section{Matching against infinity}
The equation 
$[ s \infty = \infty $
needs to be taken into account when evaluating a function application.
So whhen the pattern $ s \; x $ is matches against $ \infty $ , $x$ will be bound to $ \infty $  
\section{Interpretation of the Size type}
One may see the size type as a coniductive data type - the dual to natural numbers, the conatural numbers.
\section{Examples}
\subsection{Sized Lists}
\begin{bsp}
$\data \List ( A : \Set ) : \Size \ra \Set $ \\
$\spc \nil : \EPi{i}{\Size}{ \List A \; (\s i)} $\\
$\spc \cons : \EPi{i}{\Size}{ A \ra \List A \; i \ra \List A \; (\s i)} $
\end{bsp}

What is the differnce between vectors and sized lists ?
The size index is only used for relativ comparisons, its not an exact number, but an upper bound.
This enables subtyping, and one can compromise by forgetting the exact size ($\infty$).
For example, splitting a vector of length n, we need to show that there exist j,k such that $j+k = n$.
With sized type, we don't need to be that exact.
\subsection{Sized natural numbers}
\begin{bsp}
$\data \Nat : \Size \ra \Set $ \\
$\zero : \EPi{i}{\Size}{ \Nat \; (\s i)} $\\
$\suc : \EPi{i}{\Size}{ \Nat \; i \ra \Nat \; (\s i)} $
\end{bsp}

\subsection{Great common divisor}

\subsection{Quicksort}

\subsection{Sized ordinal numbers}
Note that sized types are quite powerful. 
We can show the termination of ordinal addition with a decreasing size argument.
First, sized Brouwer Ordinals:
\begin{bsp}
$\data \Ord : \Set$ \\
$\spc \ozero : \Ord $\\
$\spc \olim : (\Nat \ra \Ord ) \ra \Ord $
\end{bsp}
Now we don't kneed Axiom 2 of the structual ordering to see that addition is terminating:
\begin{bsp}
$\fun \addOrd : \Ord \infty \ra \EPi{i}{\Size}{\Ord i \ra \Ord \infty }$\\
$\spc \addOrd x \inacc{\s i}\; (\ozero i) = \ozero i $\\
$\spc \addOrd x \inacc{\s i}\; (\olim f)  = \olim \infty ( \lam{y} \addOrd  x \; i \; (f \; y))  $
\end{bsp}

\section{Admissibility}
\subsection{Motivation}
The use of sizes needs to be constraint.
Consider for example the function definition

\begin{bsp}
$\fun \bad : \EPi{i}{\Size}{\Nat}$\\
$\spc \bad (\s i) = bad i $ 
\end{bsp}
The termination checker will hapilly tell you that $\bad$ is terminating.
The issue here is that the size argument is not really bound to any sized data type.
But there are more subtile difficulties with using the size type.
See the example in the appendix, due to A. Abel,
the type of the function shift
\begin{bsp}
$\EPi{i}{Size}{\Nat i \ra Maybe (\Nat (s i)) \ra (Nat \ra Maybe (Nat i))} $ 
\end{bsp}
needs to be rejected by an admissibility checker.
Otherwise, a non terminating term can be constructed.
\subsection{Admissibility criterion}
Gimenez and Barthe deal with monotonicity criterions.
Abel and Pareto have worked on criterions based on continuity.
\begin{definition}
A Type $A$ is \emph{inductive in i} if it is of the form $ \DD \vec{p} \; i \: \vec{v} $ and $\DD$ is a sized inductive type
\end{definition}
\begin{definition}
A type $A$ is \emph{monotone in i} if $ \LeqVal{A}{A[i \ra \s i ]}$ 
\end{definition}
\begin{definition}
A type $A$ is \emph{antitone in i} if $ \LeqVal{A[i \ra \s i ]}{A}$ 
\end{definition}
Note that if a type is inductive in $i$, it is also monotone in $i$. 
Now we give a criterion for when a $\fun$ declaration is admissible.
\begin{definition}
A recursive function with type $ A_1 \ra \dots A_n \ra R $ is admissible, if
for every $A_j$ of the form $(i : \Size )$ , for $A_{j + 1} \ra \dots \ra R $ the following holds 
\begin{itemize}
\item
every argument $A_k$ is antitone or inductive in $i$
\item
at least one argument $A_k$ is inductive in $i$
\item
the result $R$ is monotone in $i$  
\end{itemize}
\end{definition}
\subsection{Examples}
We first give an example to show why we limit the form of what a sized type is.
Had we definied the sized natural numbers this way:
\begin{bsp}
$\data \BadNat ( A : \Set ) : \Size \ra \Set $ \\
$\spc \zero : \EPi{i}{\Size}{ \BadNat A \; i} $\\
$\spc \suc : \EPi{i}{\Size}{\BadNat i \ra \BadNat \; (\s i)} $
\end{bsp}
If the systemn accepted this as a sized type, then the following function would be seen terminating and admissible, while obviously looping on $\zero$.
\begin{bsp}
$\fun \foo : \EPi{i}{\Size}{\BadNat i \ra \Empty}$\\
$\spc \foo \inacc{(\s i)} \; (\zero (\s i) = \foo i \; (\zero i)$\\
$\spc \foo \inacc{(\s i)}\; (\suc i x) = \foo i \; x$
\end{bsp}
In our system, the $\BadNat$ type above is not a sized type, so the function $\foo$ is not admissible because $\BadNat i$ is not inductive in $i$.\\
For the same reason, the following function definition is also not admissible:
\begin{bsp}
$\fun \foo : \EPi{i}{\Size}{\Nat (\s i) \ra \Empty}$\\
$\spc \foo \inacc{(\s i)} \; (\zero (\s i) = \foo i \; (\zero i)$\\
$\spc \foo \inacc{(\s i)}\; (\suc i x) = \foo i x; l$
\end{bsp}
While $\Nat$ is a sized type, $\Nat (\s i)$ is not inductive in $i$.
\section{Subtyping for size}
It would be quite nice to have subtyping on sized data types.
As we are only interested in size arguments getting smaller, 
In one call to the function, the size might decrease by one, in another clause, by two.
It is enough for termination to decrease by one.
There is natural order on size expressions.
The special rules for subtyping are given in table x.
There are rules for function type and data types.
Otherwise, it's identical to convetability of types.  
\begin{figure}[p]
\[
\begin{array}{c}
	  \infer{i \preceq \infty}
          {}
\end{array}
\]
\[
\begin{array}{c}
	  \infer{i \preceq \s i}
          {}
\end{array}
\]
\[
\begin{array}{c}
	  \infer{i \preceq k}
          {i \preceq j & j \preceq k}
\end{array}
\]
\caption{Size comparison}
\end{figure}


\begin{figure}[p]
\[
\begin{array}{c}
	  \infer{\LeqVal{\dd \vec{v1} \; i \; \vec{v2}}{\dd \vec{v1'} \; j \; \vec{v2'}}}
	      {i \preceq j & \EqVal{\vec{v1}}{\vec{v1'}}}
\end{array}\dd \; \data
\]
\[
\begin{array}{c}
	  \infer{\LeqVal{\dd \vec{v1} \; i \; \vec{v2}}{\dd \vec{v1'} \; j \; \vec{v2'}}}
	      {j \preceq i & \EqVal{\vec{v1}}{\vec{v1'}}}
\end{array}
\dd \; \codata
\]
\caption{Subtyping for sized types}
\end{figure}

\chapter{Adding coinductive types}

Coinductive types allow the introduction of (possibly) infinite objects in type theory.
The analogon to list are colists. This type includes all finite and infinite lists.
The list of all natural numbers is an example of an infinite colist.
While we can't look at all natural numbers in a finite time, we should expect to be able to
compute any finite part of a colist in finite time.
Functions that define corecursive objects are corecustive functions.
This is possible for \emph{productive} coinductive definitions.
There are syntactic criteria for checking productivity of coinductive definitons.
But in the following, we will use the size type introduced earlier to prove termination.

\begin{itemize}
\item
coinductive datatype:
\[\codata \; \DD \; \tau : t \; \vec{\gamma}\]  

\item
coinductive function:
\[\cofun \; \ff \; : \; t \; \vec{\kappa}\]
\end{itemize}

\section{Syntax}

\section{Lazy values}
Unrolling of corecursive functions needs to be restricted.
Force is used in specific places.

\section{Arity}

\section{Examples}

\subsection{Streams}
Now we introduce streams of natural numbers.
\begin{bsp}
$\codata Stream : \Set $ \\
$\spc \cons : \Nat \ra \Stream \ra \Stream $
\end{bsp}
Note that because $\Stream$ has only one constructor, there are no finite $\Stream$ objects.
A stream of zeroes can be generated by:
\begin{bsp}
$\cofun \ones: \Stream $ \\
$\spc \ones = : \cons \zero \ones$
\end{bsp}

An example of an unproductive stream is $\unp$:
\begin{bsp}
$\cofun \unp : \Stream $ \\
$\spc \unp = : \unp$
\end{bsp}
We can look at any element of $\ones$ .
But looking at a element $\unp$ is not defined. 
A syntactic criterion for productivity of coinductive definitions is the guardness condition:
Every (co)recursive call must be guarded by a constructor.
In the above example , the call to $\ones$ is guarded by $\cons$
But we want to use sized types for productivity checking.
\subsection{Sized Streams}
Let us now explain how sized types , in comnbination with the current terminatin criterion, can be used for showing productivity.
First we introduce the sized coinductive type 
\begin{bsp}
$\codata \Stream : \Size \ra \Set $ \\
$\spc \cons : \EPi{i}{\Size}{\Nat \ra \Stream i \; \ra \Stream (\s i) } $
\end{bsp}
For the productive stream $\ones$, we turn it into
\begin{bsp}
$\cofun \ones: \EPi{i}{Size}{\Stream i} $ \\
$\spc \ones (\s i) = \cons i \zero (\ones i)$\\
$\spc \const \ones \Stream \infty = \ones \infty $
\end{bsp}
The termination checker sees that the recursive call happens on a smaller size.
For the unproductive stream, we have two bad choices:
The first one
\begin{bsp}
$\cofun \unp : \EPi{i}{\Size}{\Stream i}$ \\
$\spc \unp i =  \unp i$
\end{bsp}
is type correct, but the call is not on a smaller size.
The second option is
\begin{bsp}
$\cofun \unp : \EPi{i}{\Size}{\Stream i}$ \\
$\spc \unp (\s i) = \unp i $
\end{bsp}
is accepted by the termination checker, but thankfully is not type correct.
\subsection{Fibonacci stream}

Helper functions head, tail:
\begin{bsp}
$\norec \tail : \EPi{i}{\Size}\Stream (\s i) \ra \Stream i$\\
$\spc \tail \; .i \; (\cons A \; i \; n \; ns) = ns$\\
$\norec \head : \EPi{i}{\Size}\Stream (\s i) \ra \Nat$\\
$\spc \head \; .i \; (\cons A \; i \; n \; ns) = n$
\end{bsp}
Note that these a $\norec$ functions because they are not recursive. Besides, their type would not be admissble as a $\fun$.
We can now define looking up the nth element of a Stream.
\begin{bsp}
$\fun nth : \Nat -> \Stream \infty -> \Nat$\\
$\nth \zero ns = \head \infty ns$\\
$\nth (\suc n) \; ns = nth n (\tail \infty ns)$\\
\end{bsp}
Then, we introduce the helper function $\zipWith$:
\begin{bsp}
$\cofun \zipWith : (\Nat \ra \Nat ) \ra \EPi{i}{\Size}{\Stream i \ra \Stream i \ra \Stream i}$ \\
$\spc \zipWith f \; (\s i) \; as bs = \cons i \; (f \; a \; b) (\zipWith f \; i \; (\tail i \; as) (\tail i \; bs)$
\end{bsp}
Finally we can define the stream of all fibonacci streams:
\begin{bsp}
$\cofun \fib : \EPi{i}{\Size}\Stream i$\\
$\spc \fib (\s \s i) = \cons (\s i) \; \zero (\cons i \; (\suc \zero)$\\
$\spcx (\zipWith \add \; i \; (\fib i) \; (\tail i (\fib (\s i)))))$
\end{bsp}
and get the fourth fibonacci number by:
\begin{bsp}
$\const \fibf : \Nat = \nth (\suc (\suc (\suc (\suc \zero )))) \; (\fib \infty)$
\end{bsp}
\subsection{Stream processors}
\subsection{Colists and conatural numbers}
\section{Admissibility}
We now have to define when a $\cofun$ declaration is admissible.
\begin{definition}
A corecursive function with type $ A_1 \ra \dots A_n \ra R $ is admissible, if
for every $A_j$ of the form $(i : \Size )$ , for $A_{j + 1} \ra \dots \ra R $ the following holds 
\begin{itemize}
\item
every argument $A_k$ is antitone or inductive in $i$
\item
the result $R$ is coinductive in $i$  
\end{itemize}
\end{definition}
It follows from the definition that one can only use on size argument, because it has to be coinductive in the result type.
\chapter{Implementation}
MiniAgda was implemented in the function language Haskell \cite{haskell}.
\section{Overview}
\begin{itemize}
\item
\texttt{Abstract.hs} : Syntax for expressions , patterns, and declarations
\item
\texttt{Values.hs} : Values and related functions: eval, whnf 
\item
\texttt{TypeChecker.hs} : TypeChecking with Admissiblity checking
\item
\texttt{Termination.hs} : structural Termination checker
\item
Main.hs : the main module
\item
\text{example} dir: example input files
\end{itemize}

\section{Usage}

\begin{itemize}
\item
lists of constructors and clauses are grouped with brackets \texttt{\{},\texttt{\}} and separated with semicolon \texttt{;}
\item
$\EPi{x}{A}{B}$ is written \texttt{(x : A) -> B }
\item
$A \ra B$ is written \texttt{A -> B}
\item
$ \lam{x}e$ is written \texttt{\\ x -> e }
\item
$ \inacc{e}$ is written \texttt {.e} 
\item
$ \infty$ is written \texttt{\#} 
\item
$\s$ is written \texttt{\$}
\end{itemize}
\texttt{const} can be replaced with {\texttt {eval const}}. Then the value will be evaluated after type checking is done.
As an example showing all syntactial features, here is the fibonacci stream example (\texttt{examples/fib.ma}) in ASCII format:
\begin{verbatim}
data Nat : Set {
  zero : Nat;
  succ : Nat -> Nat 
}

fun add : Nat -> Nat -> Nat {
  add zero = \y -> y;
  add (succ x) = \y -> succ (add x y)
}

codata Stream : Size -> Set {
  cons : (i : Size) -> Nat -> Stream i -> Stream ($ i)
}
 
norec tail : (i : Size) -> Stream ($ i) -> Stream i {
  tail .i (cons i n ns) = ns
}

norec head : (i : Size) -> Stream ($ i) -> Nat {
  head .i (cons i n ns) = n
}

cofun zipWith :  (Nat -> Nat -> Nat ) -> ( i : Size ) 
		-> Stream i -> Stream i -> Stream i {
  zipWith f ($ i) as bs = 
	cons i (f (head i as) (head i bs))  (zipWith f i (tail i as) (tail i bs)) 
}

fun nth : Nat -> Stream # -> Nat {
  nth zero ns = head # ns;
  nth (succ x) ns = nth x (tail # ns) 
}

cofun fibs : ( i : Size ) -> Stream i
{
  fibs ($ $ i) = cons ($ i) zero (cons i (succ zero)
	 	(zipWith add i (fibs i) (tail i (fibs ($ i)))))
}

const 4 : Nat = (succ (succ (succ (succ zero))))
-- fib(4) = 3 
eval const fib4 : Nat = nth 4 (fibs #) 

\end{verbatim}
Running \texttt{Main examples/fib.ma} yields the console output:
\begin{verbatim}
./Main examples/fib.ma
***** MiniAgda v1.0 *****
--- scope checking ---
--- termination checking ---
--- type checking ---
Stream is a sized type 
--- evaluating constants ---
fib4 evaluates to (succ (succ (succ zero)))

\end{verbatim}

\section{Parsing}
The alex \cite{alex} and happy \cite{happy} tools where used for generating lexer and parser.

The checkers use monad transformers (\cite{Grabmueller2006MonadTransformers}).

\section{Scope checking}
The first step after parsing is scope checking. This checks that names are used correctly:
all declared constants should have a uniquie name and variables bound by 
The use of linear patterns is also restricted at scope checking.
Thus, all used identifiers can be categorized as refering to a constructor, a variable or a definied data type or
function.
After scope checking, it is guaranteed that looking up in signature or environments is guaranteed to succeed.
\subsection{Type Checking}
Type checking was implemented as explained above.
\subsection{Termination Checking}
Termination checking was implemented as explained.